---
sidebar_position: 4
---

# Getting Started

This guide will help you get VM-X AI up and running locally using Docker Compose. This is the fastest way to start exploring VM-X AI's features.

## Prerequisites

Before you begin, ensure you have:

- **Docker** and **Docker Compose** installed
- At least **4GB of free RAM** available
- **Docker images** built or pulled:
  - `vmxai/api:latest`
  - `vmxai/ui:latest`

## Quick Start

### 1. Pull Docker Images

Pull the published Docker images:

```bash
docker pull vmxai/api:latest
docker pull vmxai/ui:latest
```

### 2. Create Docker Compose File

Create a file named `docker-compose.yml` in a directory of your choice:

```yaml
name: vm-x-ai-default
version: "1.0.0"

services:
  # -------------------------------
  # Next.js (UI)
  # -------------------------------
  ui:
    image: vmxai/ui:latest
    ports:
      - "3001:3001"
    environment:
      # Auth
      AUTH_URL: http://localhost:3001
      
      # Generated by `npx auth`. Read more: https://cli.authjs.dev
      AUTH_SECRET: "iK0aiF1Hc57/P4Jym7Dz51sjlleE6onQXcAFBG7uvss"
      AUTH_OIDC_ISSUER: http://localhost:3000/oauth2
      AUTH_OIDC_CLIENT_ID: ui
      AUTH_OIDC_CLIENT_SECRET: ui
      AUTH_REDIRECT_PROXY_URL: http://localhost:3001/api/auth

      # API (network mode: host)
      API_BASE_URL: http://localhost:3000
    network_mode: host
    depends_on:
      - api

  # -------------------------------
  # Node.js (API)
  # -------------------------------
  api:
    image: vmxai/api:latest
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - redis
      - timeseriesdb
    network_mode: host
    environment:
      LOCAL: true
      BASE_URL: http://localhost:3000

      # PG Database
      DATABASE_HOST: localhost
      DATABASE_RO_HOST: localhost
      DATABASE_PORT: 5440
      DATABASE_USER: admin
      DATABASE_PASSWORD: password
      DATABASE_DB_NAME: vmxai

      # Redis (network mode: host)
      REDIS_HOST: localhost
      REDIS_PORT: 6379
      REDIS_MODE: "single"

      # Vault
      ENCRYPTION_PROVIDER: libsodium
      
      # Libsodium openssl rand -base64 32
      # Only used for development
      LIBSODIUM_ENCRYPTION_KEY: mPpddUYSuhIkuLq6MqeARZSEBZiwWm0HwEGQD5YSMFc=

      # Timeseries Database
      COMPLETION_USAGE_PROVIDER: questdb

      # QuestDB
      QUESTDB_HOST: localhost
      QUESTDB_PORT: 8812
      QUESTDB_USER: admin
      QUESTDB_PASSWORD: password
      QUESTDB_DB_NAME: vmxai

      # UI
      UI_BASE_URL: http://localhost:3001

      OTEL_LOG_LEVEL: error
      OTEL_EXPORTER_OTLP_ENDPOINT: http://localhost:4318

  # -------------------------------
  # Postgres (Database)
  # -------------------------------
  postgres:
    image: postgres
    ports:
      - '5440:5432'
    environment:
      POSTGRES_USER: 'admin'
      POSTGRES_PASSWORD: password
      POSTGRES_DB: vmxai

  # -------------------------------
  # Redis (Cache)
  # -------------------------------
  redis:
    image: redis:7
    ports:
      - '6379:6379'
    network_mode: host

  # -------------------------------
  # QuestDB (Timeseries Database)
  # -------------------------------
  timeseriesdb:
    image: questdb/questdb:9.1.1
    environment:
      QDB_PG_USER: admin
      QDB_PG_PASSWORD: password
      QDB_PG_DATABASE: vmxai
    ports:
      - '9000:9000'
      - '8812:8812'
```

### 3. Start Services

Start all services:

```bash
docker compose up -d
```

:::info Network Mode: Host
The `network_mode: host` configuration is used for the UI, API, and Redis services to simplify networking in local development. This allows services to communicate using `localhost` directly. In production deployments (Kubernetes, ECS), you should use standard Docker networking instead.
:::

This will start:
- **UI** on port `3001`
- **API** on port `3000`
- **PostgreSQL** on port `5440`
- **Redis** on port `6379`
- **QuestDB** on port `9000` (web console) and `8812` (PostgreSQL wire)

### 4. Wait for Services to Be Ready

Wait a few moments for all services to start. You can check the status:

```bash
docker compose -f default.docker-compose.yml ps
```

Check the API logs to ensure it's ready:

```bash
docker compose -f default.docker-compose.yml logs api | grep "Application is running"
```

### 5. Access the Application

Open your browser and navigate to:

**UI**: http://localhost:3001

The default credentials are:
- **Username**: `admin`
- **Password**: `admin`

:::warning
Change the default credentials immediately after first login!
:::

## What's Next?

After logging in, you'll be guided through the setup process:

1. **Create a Workspace** (if none exists)
2. **Create an Environment** (if none exists)
3. **Create an AI Connection** - Add your first AI provider
4. **Create an AI Resource** - Configure your first resource
5. **Generate an API Key** - Get an API key to use with your applications

## Using the OpenAI-Compatible API

VM-X AI uses workspace and environment isolation for the completion API. The API endpoint includes the workspace ID and environment ID in the path.

### Getting Your Workspace and Environment IDs

1. Log in to the UI at http://localhost:3001
2. Navigate to your workspace and environment
3. Copy the workspace ID and environment ID from the URL: `/workspaces/{workspaceId}/{environmentId}/...`

### Python Example

```python
from openai import OpenAI

workspace_id = "6c41dc1b-910c-4358-beef-2c609d38db31"
environment_id = "6c1957ca-77ca-49b3-8fa1-0590281b8b44"
resource_name = "your-resource-name"  # The name of your AI Resource

client = OpenAI(
    api_key="your-vmx-api-key-here",
    base_url=f"http://localhost:3000/v1/completion/{workspace_id}/{environment_id}"
)

response = client.chat.completions.create(
    model=resource_name,
    messages=[
        {"role": "user", "content": "Hello, world!"}
    ]
)

print(response.choices[0].message.content)
```

### Node.js Example

```javascript
import OpenAI from 'openai';

const workspaceId = "6c41dc1b-910c-4358-beef-2c609d38db31";
const environmentId = "6c1957ca-77ca-49b3-8fa1-0590281b8b44";
const resourceName = "your-resource-name"; // The name of your AI Resource

const openai = new OpenAI({
  apiKey: 'your-vmx-api-key-here',
  baseURL: `http://localhost:3000/v1/completion/${workspaceId}/${environmentId}`,
});

const completion = await openai.chat.completions.create({
  model: resourceName,
  messages: [{ role: 'user', content: 'Hello, world!' }],
});

console.log(completion.choices[0].message.content);
```

### cURL Example

```bash
curl http://localhost:3000/v1/completion/{workspaceId}/{environmentId}/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-vmx-api-key-here" \
  -d '{
    "model": "your-resource-name",
    "messages": [
      {"role": "user", "content": "Hello, world!"}
    ]
  }'
```

## Additional Docker Compose Configurations

For more advanced configurations, see the [examples/docker-compose](../../examples/docker-compose/README.md) directory which contains:

### Default Configuration

**File**: `default.docker-compose.yml`

Basic setup with all core services:
- PostgreSQL
- Redis (single node)
- QuestDB
- Libsodium encryption

**Usage**:
```bash
docker compose -f default.docker-compose.yml up
```

### OpenTelemetry Configuration

**File**: `otel.docker-compose.yml`

Full observability stack:
- All services from default
- OpenTelemetry Collector
- Jaeger (tracing)
- Prometheus (metrics)
- Loki (logs)
- Grafana (dashboards)

**Usage**:
```bash
docker compose -f otel.docker-compose.yml up
```

**Access URLs**:
- Jaeger UI: http://localhost:16686
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3010
- QuestDB Console: http://localhost:9000

### AWS Services Configuration

**File**: `aws.docker-compose.yml`

Production-like setup using AWS services:
- AWS KMS for encryption
- AWS Timestream for time-series data
- Requires AWS credentials configured

**Usage**:
```bash
# Set AWS credentials
export AWS_ACCESS_KEY_ID=your-access-key-id
export AWS_SECRET_ACCESS_KEY=your-secret-access-key
export AWS_REGION=us-east-1

docker compose -f aws.docker-compose.yml up
```

### Redis Cluster Configuration

**File**: `redis-cluster.docker-compose.yml`

Redis cluster mode for high availability:
- 3-node Redis cluster
- QuestDB
- Libsodium encryption

**Usage**:
```bash
docker compose -f redis-cluster.docker-compose.yml up
```

## Configuration

### Environment Variables

Key environment variables for the API service:

| Variable | Description | Default |
|----------|-------------|---------|
| `BASE_URL` | API base URL | `http://localhost:3000` |
| `DATABASE_HOST` | PostgreSQL host | `localhost` |
| `DATABASE_PORT` | PostgreSQL port | `5440` |
| `REDIS_HOST` | Redis host | `localhost` |
| `REDIS_PORT` | Redis port | `6379` |
| `REDIS_MODE` | Redis mode (`single` or `cluster`) | `single` |
| `ENCRYPTION_PROVIDER` | Encryption provider (`libsodium` or `aws-kms`) | `libsodium` |
| `COMPLETION_USAGE_PROVIDER` | Time-series provider (`questdb` or `aws-timestream`) | `questdb` |
| `OTEL_ENABLED` | Enable OpenTelemetry | `false` |

### Database Credentials

Default credentials (change in production!):

- **PostgreSQL**:
  - User: `admin`
  - Password: `password`
  - Database: `vmxai`

- **QuestDB**:
  - User: `admin`
  - Password: `password`
  - Database: `vmxai`

- **Redis**: No password (development only)

## Stopping Services

To stop all services:

```bash
docker compose -f default.docker-compose.yml down
```

To stop and remove volumes (⚠️ deletes data):

```bash
docker compose -f default.docker-compose.yml down -v
```

## Troubleshooting

### Port Conflicts

If you encounter port conflicts, you can modify the port mappings in the compose file:

```yaml
ports:
  - "3001:3001"  # Change 3001 to an available port
```

### Services Not Starting

Check service logs:

```bash
# Check all logs
docker compose -f default.docker-compose.yml logs

# Check specific service
docker compose -f default.docker-compose.yml logs api
docker compose -f default.docker-compose.yml logs ui
```

### Database Connection Issues

Ensure PostgreSQL is ready before the API starts:

```bash
# Check PostgreSQL status
docker compose -f default.docker-compose.yml ps postgres

# Check PostgreSQL logs
docker compose -f default.docker-compose.yml logs postgres
```

### Redis Connection Issues

For Redis cluster mode, ensure the cluster is initialized:

```bash
# Check cluster init logs
docker compose -f redis-cluster.docker-compose.yml logs redis-cluster-init
```

## Next Steps

Now that you have VM-X AI running locally:

1. **[Create Your First AI Connection](./features/ai-connections.md)** - Add an AI provider
2. **[Create Your First AI Resource](./features/ai-resources.md)** - Configure routing and fallback
3. **[Explore Features](./features/)** - Learn about all available features
4. **[Deploy to Production](./deployment/)** - Deploy to Kubernetes or AWS

## Additional Resources

- [Docker Compose Examples README](../../examples/docker-compose/README.md) - Detailed information about all configurations
- [Core Components](./core-components.md) - Understand AI Connections and Resources
- [Architecture](./architecture.md) - Learn about the technical stack

